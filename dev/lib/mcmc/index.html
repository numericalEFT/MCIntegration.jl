<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Markov-chain Monte Carlo · MCIntegration.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://numericaleft.github.io/MCIntegration.jl/lib/mcmc/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">MCIntegration.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../montecarlo/">Main module</a></li><li><a class="tocitem" href="../vegasmc/">Markov-chain based Vegas algorithm</a></li><li><a class="tocitem" href="../vegas/">Vegas algorithm</a></li><li class="is-active"><a class="tocitem" href>Markov-chain Monte Carlo</a></li><li><a class="tocitem" href="../distribution/">Random Variables</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Reference</a></li><li class="is-active"><a href>Markov-chain Monte Carlo</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Markov-chain Monte Carlo</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/numericaleft/MCIntegration.jl/blob/master/docs/src/lib/mcmc.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Markov-chain-Monte-Carlo"><a class="docs-heading-anchor" href="#Markov-chain-Monte-Carlo">Markov-chain Monte Carlo</a><a id="Markov-chain-Monte-Carlo-1"></a><a class="docs-heading-anchor-permalink" href="#Markov-chain-Monte-Carlo" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="MCIntegration.MCMC.montecarlo-Union{Tuple{T}, Tuple{O}, Tuple{P}, Tuple{V}, Tuple{N}, Tuple{Configuration{N, V, P, O, T}, Function, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any, Any, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any, Any, Any, Any}} where {N, V, P, O, T}" href="#MCIntegration.MCMC.montecarlo-Union{Tuple{T}, Tuple{O}, Tuple{P}, Tuple{V}, Tuple{N}, Tuple{Configuration{N, V, P, O, T}, Function, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any, Any, Any}, Tuple{Configuration{N, V, P, O, T}, Function, Any, Any, Any, Any, Any}} where {N, V, P, O, T}"><code>MCIntegration.MCMC.montecarlo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">function montecarlo(config::Configuration{N,V,P,O,T}, integrand::Function, neval,
    print=0, save=0, timer=[], debug=false;
    measurefreq=2, measure::Union{Nothing,Function}=nothing, kwargs...) where {N,V,P,O,T}</code></pre><p>This algorithm calculate high-dimensional integrals with a Markov-chain Monte Carlo. For multiple integrands invoves multiple variables, it finds the best distribution ansatz to fit them all together. In additional to the original integral, it also  introduces a normalization integral with integrand ~ 1.</p><p>Assume we want to calculate the integral <span>$f_1(x)$</span> and <span>$f_2(x, y)$</span>, where x, y are two different types of variables. The algorithm will try to learn a distribution <span>$\rho_x(x)$</span> and <span>$\rho_y(y)$</span> so that <span>$f_1(x)/\rho_x(x)$</span> and <span>$f_2(x, y)/\rho_x(x)/\rho_y(y)$</span> are as flat as possible. </p><p>The algorithm then samples the variables x and y with a joint distribution using the Metropolis-Hastings algorithm, <span>$math p(x, y) = r_0 \cdot \rho_x(x) \cdot \rho_y(y) + r_1 \cdot |f_1(x)| \cdot \rho_y(y) + r_2 \cdot |f_2(x, y)|$</span> where <span>$r_i$</span> are certain reweighting factor to make sure all terms contribute same weights. One then estimate the integrals by averaging the observables <span>$f_1(x)\rho_y(y)/p(x, y)$</span> and <span>$f_2(x, y)/p(x, y)$</span>.</p><p>This algorithm reduces to the vanilla Vegas algorithm by setting <span>$r_0 = 1$</span> and <span>$r_{i&gt;0} = 0$</span>.</p><p>The key difference between this algorithmm and the algorithm <code>:vegasmc</code> is the way that the joint distribution <span>$p(x, y)$</span> is sampled. In this algorithm, one use Metropolis-Hastings algorithm to sample each term in <span>$p(x, y)$</span> as well as the variables <span>$(x, y)$</span>, so that the MC configuration space consists of <span>$(idx, x, y)$</span>, where <span>$idx$</span> is the index of the user-defined and the normalization integrals. On the other hand, the <code>:vegasmc</code> algorithm only uses Metropolis-Hastings algorithm to sample the configuration space <span>$(x, y)$</span>. For a given set of x and y, all terms in <span>$p(x, y)$</span> are explicitly calculated on the fly. If one can afford calculating all the integrands on the fly, then <code>:vegasmc</code> should be more efficient than this algorithm.</p><p>NOTE: If there are more than one integrals, only one of them are sampled and measured at each Markov-chain Monte Carlo step!</p><p>For low-dimensional integrations, this algorithm is much less efficient than the :vegasmc or :vegas solvers. For high-dimension integrations, however, this algorithm becomes as efficent and robust as the :vegasmc solver, and is more efficient and robust than the :vegas solver.</p><p><strong>Arguments</strong></p><ul><li><code>integrand</code> : User-defined function with the following signature:</li></ul><pre><code class="language-julia hljs">function integrand(idx, var, config)
    # calculate your integrand values
    # return integrand of the index idx
end</code></pre><p>The first argument <code>idx</code> is index of the integral being sampled. The second parameter <code>var</code> is either a Variable struct if there is only one type of variable, or a tuple of Varibles if there are more than one types of variables. The third parameter passes the MC <code>Configuration</code> struct to the integrand, so that user has access to userdata, etc.</p><ul><li><code>measure</code> : User-defined function with the following signature:</li></ul><pre><code class="language-julia hljs">function measure(idx, var, obs, weight, config)
    # accumulates the weight into the observable
    # For example,
    # obs[idx] = weight # integral idx
    # ...
end</code></pre><p>The first argument <code>idx</code> is index of the integral being sampled. The second argument <code>var</code> is either a Variable struct if there is only one type of variable, or a tuple of Varibles if there are more than one types of variables. The third argument passes the user-defined observable to the function, it should be a vector with the length same as the integral number. The fourth argument is the integrand weights to be accumulated to the observable, it is a vector with the length same as the integral number. The last argument passes the MC <code>Configuration</code> struct to the integrand, so that user has access to userdata, etc.</p><p><strong>Remark:</strong></p><ul><li><p>What if the integral result makes no sense?</p><p>One possible reason is the reweight factor. It is important for the Markov chain to visit the integrals with the similar frequency.  However, the weight of different integrals may be order-of-magnitude different. It is thus important to reweight the integrals.  Internally, the MC sampler try to reweight for each iteration. However, it could fail either 1) the total MC steps is too small so that  reweighting doesn&#39;t have enough time to show up; ii) the integrals are simply too different, and the internal reweighting subroutine is  not smart enough to figure out such difference. If 1) is the case, one either increase the neval. If 2) is the case, one may mannually  provide an array of reweight factors when initializes the <code>MCIntegration.configuration</code> struct. </p></li></ul><p><strong>Examples</strong></p><p>The following command calls the MC Vegas solver,</p><pre><code class="language-julia-repl hljs">julia&gt; integrate((idx, x, c)-&gt;(x[1]^2+x[2]^2); var = Continuous(0.0, 1.0), dof = 2, print=-1, solver=:mcmc)
Integral 1 = 0.6757665376867902 ± 0.008655534861083898   (chi2/dof = 0.681)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/numericaleft/MCIntegration.jl/blob/b584d1b96902271a7a5ed82fc704eed5978e0520/src/mcmc/montecarlo.jl#L7-L86">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../vegas/">« Vegas algorithm</a><a class="docs-footer-nextpage" href="../distribution/">Random Variables »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.5 on <span class="colophon-date" title="Thursday 8 September 2022 22:18">Thursday 8 September 2022</span>. Using Julia version 1.8.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
